<!DOCTYPE html>
<html class="writer-html5" lang="en" >
<head>
    <meta charset="utf-8" />
    <meta http-equiv="X-UA-Compatible" content="IE=edge" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" />
      <link rel="shortcut icon" href="../../img/favicon.ico" />
    <title>pii_manager - Riverbed Docs</title>
    <link rel="stylesheet" href="../../css/theme.css" />
    <link rel="stylesheet" href="../../css/theme_extra.css" />
        <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/10.5.0/styles/github.min.css" />
        <link href="../../assets/_mkdocstrings.css" rel="stylesheet" />
    
      <script>
        // Current page data
        var mkdocs_page_name = "pii_manager";
        var mkdocs_page_input_path = "reference/pii_manager.md";
        var mkdocs_page_url = null;
      </script>
    
    <script src="../../js/jquery-3.6.0.min.js" defer></script>
    <!--[if lt IE 9]>
      <script src="../../js/html5shiv.min.js"></script>
    <![endif]-->
      <script src="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/10.5.0/highlight.min.js"></script>
      <script>hljs.initHighlightingOnLoad();</script> 
</head>

<body class="wy-body-for-nav" role="document">

  <div class="wy-grid-for-nav">
    <nav data-toggle="wy-nav-shift" class="wy-nav-side stickynav">
    <div class="wy-side-scroll">
      <div class="wy-side-nav-search">
          <a href="../.." class="icon icon-home"> Riverbed Docs
        </a><div role="search">
  <form id ="rtd-search-form" class="wy-form" action="../../search.html" method="get">
      <input type="text" name="q" placeholder="Search docs" title="Type search term here" />
  </form>
</div>
      </div>

      <div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="Navigation menu">
              <ul>
                <li class="toctree-l1"><a class="reference internal" href="../..">Home</a>
                </li>
              </ul>
              <ul>
                <li class="toctree-l1"><a class="reference internal" href="../../about/">About</a>
                </li>
              </ul>
              
                      <p class="caption"><span class="caption-text">Code Reference</span></p>
              
              <ul class="current">
                  <li class="toctree-l1"><a class="reference internal" href="../banned_words/">banned_words</a>
                  </li>
                  <li class="toctree-l1"><a class="reference internal" href="../char_manager/">char_manager</a>
                  </li>
                  <li class="toctree-l1"><a class="reference internal" href="../cjk/">cjk</a>
                  </li>
                  <li class="toctree-l1"><a class="reference internal" href="../filtering/">filtering</a>
                  </li>
                  <li class="toctree-l1"><a class="reference internal" href="../flagged_words/">flagged_words</a>
                  </li>
                  <li class="toctree-l1"><a class="reference internal" href="../kenlm_manager/">kenlm_manager</a>
                  </li>
                  <li class="toctree-l1"><a class="reference internal" href="../langid_manager/">langid_manager</a>
                  </li>
                  <li class="toctree-l1"><a class="reference internal" href="../pdf_and_ocr/">pdf_and_ocr</a>
                  </li>
                  <li class="toctree-l1 current"><a class="reference internal current" href="./">pii_manager</a>
    <ul class="current">
    </ul>
                  </li>
                  <li class="toctree-l1"><a class="reference internal" href="../searcher_indexer/">searcher_indexer</a>
                  </li>
                  <li class="toctree-l1"><a class="reference internal" href="../simhash/">simhash</a>
                  </li>
                  <li class="toctree-l1"><a class="reference internal" href="../stopwords/">stopwords</a>
                  </li>
                  <li class="toctree-l1"><a class="reference internal" href="../translation/">translation</a>
                  </li>
                  <li class="toctree-l1"><a class="reference internal" href="../utils/">utils</a>
                  </li>
              </ul>
      </div>
    </div>
    </nav>

    <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap">
      <nav class="wy-nav-top" role="navigation" aria-label="Mobile navigation menu">
          <i data-toggle="wy-nav-top" class="fa fa-bars"></i>
          <a href="../..">Riverbed Docs</a>
        
      </nav>
      <div class="wy-nav-content">
        <div class="rst-content"><div role="navigation" aria-label="breadcrumbs navigation">
  <ul class="wy-breadcrumbs">
    <li><a href="../.." class="icon icon-home" alt="Docs"></a> &raquo;</li>
          <li>Code Reference &raquo;</li>
      <li>pii_manager</li>
    <li class="wy-breadcrumbs-aside">
    </li>
  </ul>
  <hr/>
</div>
          <div role="main" class="document" itemscope="itemscope" itemtype="http://schema.org/Article">
            <div class="section" itemprop="articleBody">
              
                <div class="doc doc-object doc-module">


<a id="pii_manager"></a>
  <div class="doc doc-contents first">

  

  <div class="doc doc-children">







<div class="doc doc-object doc-attribute">



<h2 id="pii_manager.lang_2_country" class="doc doc-heading">
<code class="highlight language-python">lang_2_country = {'am': ['et'], 'ar': ['ae', 'iq', 'dz', 'eg', 'sd', 'aa', 'il', 'ps', 'sa', 'bh', 'km', 'dj', 'er', 'eh', 'jo', 'kw', 'lb', 'ly', 'ma', 'mr', 'om', 'qa', 'so', 'sy', 'td', 'tn', 'ye'], 'ay': ['bo'], 'az': ['az'], 'be': ['by'], 'bg': ['bg'], 'bi': ['vu'], 'bn': ['bd'], 'bs': ['ba'], 'ca': ['ad'], 'ch': ['gu'], 'cs': ['cz'], 'da': ['dk'], 'de': ['at', 'ch', 'de', 'be', 'li', 'lu'], 'dv': ['mv'], 'dz': ['bt'], 'el': ['gr', 'cy'], 'en': ['pk', 'sd', 'au', 'ca', 'gb', 'gh', 'ie', 'in', 'nz', 'us', 'ai', 'as', 'ag', 'bi', 'bs', 'bz', 'bm', 'bb', 'bw', 'cc', 'cm', 'ck', 'cx', 'ky', 'dm', 'er', 'fj', 'fk', 'fm', 'gg', 'gi', 'gm', 'gd', 'gu', 'gy', 'hk', 'im', 'io', 'jm', 'je', 'ke', 'ki', 'kn', 'lr', 'lc', 'ls', 'mg', 'mh', 'mt', 'mp', 'ms', 'mu', 'mw', 'na', 'nf', 'ng', 'nu', 'nr', 'pn', 'ph', 'pw', 'pg', 'pr', 'rw', 'sg', 'sh', 'sb', 'sl', 'ss', 'sz', 'sx', 'sc', 'tc', 'tk', 'to', 'tt', 'tv', 'tz', 'ug', 'um', 'vc', 'vg', 'vi', 'vu', 'ws', 'za', 'zm', 'zw'], 'es': ['ar', 'es', 'mx', 'bo', 'cl', 'co', 'cr', 'cu', 'do', 'ec', 'gq', 'gt', 'hn', 'ni', 'pa', 'pe', 'pr', 'py', 'sv', 'uy', 've'], 'et': ['ee'], 'fa': ['ir', 'af'], 'fi': ['fi'], 'fil': ['ph'], 'fj': ['fj'], 'fo': ['fo'], 'fr': ['dz', 'ca', 'ch', 'fr', 'qc', 'bi', 'be', 'bj', 'bf', 'bl', 'cf', 'ci', 'cm', 'cd', 'cg', 'km', 'dj', 'ga', 'gn', 'gp', 'gq', 'gf', 'ht', 'lu', 'mf', 'ma', 'mc', 'mg', 'ml', 'mq', 'mu', 'yt', 'nc', 'ne', 'pf', 're', 'rw', 'sn', 'pm', 'sc', 'sy', 'td', 'tg', 'tn', 'vu', 'wf'], 'ga': ['ie'], 'gil': ['ki'], 'gn': ['py'], 'gsw': ['ch', 'li'], 'gv': ['im'], 'he': ['il'], 'hi': ['in'], 'hif': ['fj'], 'ho': ['pg'], 'hr': ['hr', 'ba'], 'ht': ['ht'], 'hu': ['hu'], 'hy': ['am'], 'id': ['id'], 'is': ['is'], 'it': ['ch', 'it', 'sm', 'va'], 'ja': ['jp'], 'ka': ['ge'], 'kk': ['kz'], 'kl': ['gl'], 'km': ['kh'], 'ko': ['kr', 'kp'], 'ky': ['kg'], 'lb': ['lu'], 'lo': ['la'], 'lt': ['lt'], 'lv': ['lv'], 'mg': ['mg'], 'mh': ['mh'], 'mi': ['nz'], 'mk': ['mk'], 'mn': ['mn'], 'ms': ['bn', 'my', 'sg'], 'mt': ['mt'], 'my': ['mm'], 'na': ['nr'], 'nb': ['no', 'sj'], 'nd': ['zw'], 'ne': ['np'], 'niu': ['nu'], 'nl': ['nl', 'aw', 'be', 'bq', 'cw', 'sr', 'sx'], 'nn': ['no'], 'ny': ['mw'], 'pap': ['aw', 'cw'], 'pau': ['pw'], 'pl': ['pl'], 'ps': ['af'], 'pt': ['br', 'pt', 'ao', 'cv', 'gw', 'gq', 'mo', 'mz', 'st', 'tl'], 'qu': ['bo', 'ec', 'pe'], 'rn': ['bi'], 'ro': ['ro', 'md'], 'ru': ['ru', 'ua', 'by', 'kz', 'kg'], 'rw': ['rw'], 'sg': ['cf'], 'si': ['lk'], 'sk': ['sk'], 'sl': ['si'], 'sm': ['as', 'ws'], 'sn': ['zw'], 'so': ['so'], 'sq': ['al'], 'sr': ['ba', 'me', 'rs'], 'ss': ['sz'], 'st': ['ls'], 'sv': ['fi', 'se', 'ax'], 'sw': ['ke', 'tz', 'ug'], 'ta': ['lk', 'sg'], 'tet': ['tl'], 'tg': ['tj'], 'th': ['th'], 'ti': ['er'], 'tk': ['tm'], 'tkl': ['tk'], 'tn': ['bw'], 'to': ['to'], 'tpi': ['pg'], 'tr': ['tr', 'cy'], 'tvl': ['tv'], 'ty': ['pf'], 'tzm': ['ma'], 'uk': ['ua'], 'ur': ['pk'], 'uz': ['uz'], 'vi': ['vn'], 'wni': ['km'], 'wo': ['sn'], 'yo': ['ng'], 'zdj': ['km'], 'zh': ['cn', 'tw', 'hk', 'mo', 'sg']}</code>
  
  <span class="doc doc-labels">
      <small class="doc doc-label doc-label-module-attribute"><code>module-attribute</code></small>
  </span>

</h2>


  <div class="doc doc-contents ">
  
      <p>Copyright, 2021-2022 Ontocord, LLC, All rights reserved.
Licensed under the Apache License, Version 2.0 (the "License");
you may not use this file except in compliance with the License.
You may obtain a copy of the License at
    http://www.apache.org/licenses/LICENSE-2.0
Unless required by applicable law or agreed to in writing, software
distributed under the License is distributed on an "AS IS" BASIS,
WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
See the License for the specific language governing permissions and
limitations under the License.</p>
  </div>

</div>



<div class="doc doc-object doc-function">



<h2 id="pii_manager.detect_ner_with_regex_and_context" class="doc doc-heading">
<code class="highlight language-python">detect_ner_with_regex_and_context(sentence, src_lang, tag_type=None, prioritize_lang_match_over_ignore=True, ignore_stdnum_type={'isil', 'isbn', 'isan', 'imo', 'gs1_128', 'grid', 'figi', 'ean', 'casrn', 'cusip'}, all_regex=None, context_window=20, min_id_length=6, max_id_length=50, precedence={'PHONE': 1, 'IP_ADDRESS': 2, 'DATE': 3, 'TIME': 4, 'LICENSE_PLATE': 5, 'USER': 6, 'AGE': 7, 'ID': 8, 'KEY': 9, 'ADDRESS': 10, 'URL': 11, 'EQUATION': 12})</code>

</h2>


  <div class="doc doc-contents ">
  

<details class="output">
  <summary>Output</summary>
  <ul>
<li>This function returns a list of 4 tuples, representing an NER detection for [(entity, start, end, tag), ...]</li>
</ul>
</details>
<details class="input">
  <summary>Input</summary>
  <p>:sentence: any text, including a sentence or a document to tag
:src_lang: the language of the sentence
:context_window: the contxt window in characters to check for context characters for any rules that requries context
:max_id_length: the maximum length of an ID
:min_id_length: the minimum length of an ID
:tag_type: the type of NER tags we are detecting. If None, then detect everything.
:ignore_stdnum_type: the set of stdnum we will consider NOT PII and not match as an ID
:prioritize_lang_match_over_ignore: if true, and an ID matches an ingore list, we still keep it as an ID if there was an ID match for this particular src_lang
:all_regex: a rulebase of the form {tag: {lang: [(regex, context, block), ...], 'default': [(regex, context, block), ...]}}. 
  context are words that must be found surronding the entity. block are words that must not be found.
  If all_regex is none, then we use the global regex_rulebase</p>
</details>
<details class="algorithm">
  <summary>ALGORITHM</summary>
  <p>For each regex, we check the sentence to find a match and a required context, if the context exists in a window.
If the regex is an ID or a DATE, test to see if it's a stdnum we know. Stdnum are numbers formatted to specific regions, or generally.
If it is a stdnum and NOT a PII type (such as ISBN numbers) skip this ID.
  UNLESS If the stdnum is ALSO a PII type for the local region of the language, then consider it a matched stdnum.
If it's a matched stdnum that is not skipped, save it as an ID.
If the ID is not a stdum, check if the ID is a DATE. If it's a DATE using context words in a context window. 
  If it's a DATE then save it as a DATE, else save as ID.
Gather all regex matches and sort the list by position, prefering longer matches, and DATEs and ADDRESSES over IDs.
For all subsumed IDs and DATEs, remove those subsumed items. 
Return a list of potentially overlapping NER matched.</p>
</details>      <p>NOTE: 
- There may be overlaps in mention spans. 
- Unlike presidio, we require that a context be met. We don't increase a score if a context is matched.<br />
- A regex does not need to match string boundaries or space boundaries. The matching code checks this. 
    We require all entities that is not cjk to have space or special char boundaries or boundaries at end or begining of sentence.
- As such, We don't match embedded IDs: e.g., MyIDis555-555-5555 won't match the ID. This is to preven
  matching extremely nosiy imput that might have patterns of numbers in long strings.</p>

      <details class="quote">
        <summary>Source code in <code>src/pii_manager.py</code></summary>
        <pre class="highlight"><code class="language-python">def detect_ner_with_regex_and_context(sentence, src_lang,  tag_type= None, prioritize_lang_match_over_ignore=True, \
      ignore_stdnum_type={'isil', 'isbn', 'isan', 'imo', 'gs1_128', 'grid', 'figi', 'ean', 'casrn', 'cusip' }, \
      all_regex=None, context_window=20, min_id_length=6, max_id_length=50, \
      precedence={'PHONE':1, 'IP_ADDRESS':2, 'DATE':3, 'TIME':4, 'LICENSE_PLATE':5, 'USER':6, 'AGE':7, 'ID':8, 'KEY': 9,  'ADDRESS':10, 'URL':11, 'EQUATION': 12}):
      """
      Output:
       - This function returns a list of 4 tuples, representing an NER detection for [(entity, start, end, tag), ...]
      Input:
       :sentence: any text, including a sentence or a document to tag
       :src_lang: the language of the sentence
       :context_window: the contxt window in characters to check for context characters for any rules that requries context
       :max_id_length: the maximum length of an ID
       :min_id_length: the minimum length of an ID
       :tag_type: the type of NER tags we are detecting. If None, then detect everything.
       :ignore_stdnum_type: the set of stdnum we will consider NOT PII and not match as an ID
       :prioritize_lang_match_over_ignore: if true, and an ID matches an ingore list, we still keep it as an ID if there was an ID match for this particular src_lang
       :all_regex: a rulebase of the form {tag: {lang: [(regex, context, block), ...], 'default': [(regex, context, block), ...]}}. 
         context are words that must be found surronding the entity. block are words that must not be found.
         If all_regex is none, then we use the global regex_rulebase

      ALGORITHM:
        For each regex, we check the sentence to find a match and a required context, if the context exists in a window.
        If the regex is an ID or a DATE, test to see if it's a stdnum we know. Stdnum are numbers formatted to specific regions, or generally.
        If it is a stdnum and NOT a PII type (such as ISBN numbers) skip this ID.
          UNLESS If the stdnum is ALSO a PII type for the local region of the language, then consider it a matched stdnum.
        If it's a matched stdnum that is not skipped, save it as an ID.
        If the ID is not a stdum, check if the ID is a DATE. If it's a DATE using context words in a context window. 
          If it's a DATE then save it as a DATE, else save as ID.
        Gather all regex matches and sort the list by position, prefering longer matches, and DATEs and ADDRESSES over IDs.
        For all subsumed IDs and DATEs, remove those subsumed items. 
        Return a list of potentially overlapping NER matched.
      NOTE: 
      - There may be overlaps in mention spans. 
      - Unlike presidio, we require that a context be met. We don't increase a score if a context is matched.  
      - A regex does not need to match string boundaries or space boundaries. The matching code checks this. 
          We require all entities that is not cjk to have space or special char boundaries or boundaries at end or begining of sentence.
      - As such, We don't match embedded IDs: e.g., MyIDis555-555-5555 won't match the ID. This is to preven
        matching extremely nosiy imput that might have patterns of numbers in long strings.

      """

      sw = all_stopwords.get(src_lang, {})

      # if we are doing 'ID', we would still want to see if we catch an ADDRESS. 
      # ADDRESS may have higher precedence, in which case it might overide an ID match. 
      no_address = False
      if tag_type is not None and 'ID' in tag_type and 'ADDRESS' not in tag_type:
         no_address = True
         tag_type = set(list(tag_type)+['ADDRESS'])

      # if we are doing 'DATE' we would still want to do ID because they intersect.
      no_id = False
      if tag_type is not None and 'DATE' in tag_type and 'ID' not in tag_type:
         no_id = True
         tag_type = set(list(tag_type)+['ID'])

      # if we are doing 'AGE' we would still want to do DATE because they intersect.
      no_date = False
      if tag_type is not None and 'AGE' in tag_type and 'DATE' not in tag_type:
         no_date = True
         tag_type = set(list(tag_type)+['DATE'])


      is_cjk = src_lang in {'zh', 'zh-classical', 'zh-min-nan', 'zh-yue', 'ko', 'ja', 'th', 'jv'} 
      if is_cjk:
          sentence_set = set(sentence.lower())
      else:
          sentence_set = []
          #let's do a sanity check. there should be no words beyond 100 chars.
          #this will really mess up our regexes.
          for word in sentence.split(" "):
            len_word = len(word)
            if len_word &gt; 100:
              sentence = sentence.replace(word, " "*len_word)
            else:
              sentence_set.append(word.lower())
          sentence_set = set([s.strip(rstrip_chars) for s in sentence_set])
      all_ner = []
      len_sentence = len(sentence)

      if all_regex is None:
        all_regex = regex_rulebase
      if tag_type is None:
        all_tags_to_check = list(all_regex.keys())
      else:
        all_tags_to_check = list(tag_type) 

      for tag in all_tags_to_check:
          regex_group = all_regex.get(tag)
          if not regex_group: continue
          for regex_context, extra_weight in [(a, 1) for a in regex_group.get(src_lang, [])] + [(a, 0) for a in regex_group.get("default", [])]:
              if True:
                  regex, context, block = regex_context
                  #if this regex rule requires a context, find if it is satisified in general. this is a quick check.
                  potential_context = False
                  if context:
                      for c1 in context:
                        c1 = c1.lower()
                        for c2 in c1.split():
                          c2 = c2.strip(rstrip_chars)
                          if c2 in sentence_set:
                              potential_context = True
                              break
                        if potential_context: break
                      if not potential_context:
                          continue
                  #now apply regex
                  for ent in list(set(list(regex.findall(sentence)))):
                      #print (ent)
                      if not isinstance(ent, str):
                        continue
                      ent = ent.strip()
                      #ent = ent.rstrip(rstrip_chars)
                      #ent = ent.lstrip(lstrip_chars)
                      if not ent:
                        continue

                      ent_is_4_digit=False
                      len_ent = len(ent)
                      if len_ent == 4:
                        try:
                          int(ent)
                          ent_is_4_digit=True
                        except:
                          ent_is_4_digit=False
                      sentence2 = sentence
                      delta = 0
                      #check to see if the ID or DATE is type of stdnum
                      is_stdnum = False
                      if tag in ('ID', 'DATE'):
                          #simple length test
                          ent_no_space = ent.replace(" ", "").replace(".", "").replace("-", "")
                          if len(ent_no_space) &gt; max_id_length and tag == 'ID': continue
                          if len(ent_no_space) &lt; min_id_length and tag == 'ID': continue

                          #check if this is really a non PII stdnum, unless it's specifically an ID for a country using this src_lang. 
                          #TODO - complete the country to src_lang dict above. 
                          stnum_type = ent_2_stdnum_type(ent, src_lang)

                          #if the stdnum is one of the non PII types, we will ignore it
                          if prioritize_lang_match_over_ignore:
                                is_stdnum = any(a for a in stnum_type if "." in a and src_lang in country_2_lang.get(a.split(".")[0], []))
                          if not ent_is_4_digit and not is_stdnum and any(a for a in stnum_type if a in ignore_stdnum_type):
                            #a four digit entity might be a year, so don't skip this ent
                            continue
                          #this is actually an ID of known stdnum and not a DATE
                          if any(a for a in stnum_type if a not in ignore_stdnum_type):
                            tag = 'ID'
                            is_stdnum = True

                      #let's check the FIRST instance of this DATE or ID is really a date; 
                      #ideally we should do this for every instance of this ID
                      if tag == 'DATE' or (tag == 'ID' and not is_stdnum):
                        ent, tag = test_is_date(ent, tag, sentence, len_sentence, is_cjk, sentence.index(ent),  src_lang, sw)
                        if not ent: continue

                      #do some confirmation for addresses if libpostal is installed. TODO, test if this works for zh. libpostal appears to test for pinyin.
                      if tag == 'ADDRESS' and not parse_address: continue
                      if tag == 'ADDRESS' and parse_address:
                        address = parse_address(ent)

                        if address and not any(ad for ad in address if ad[1] != 'house'):
                          continue # this isn't an address

                        if address and address[0][1] == 'house':
                          address = address[1:]

                        ent_lower = ent.lower()
                        if address[0][0].lower() in ent_lower:
                              ent = ent[ent_lower.index(address[0][0]):].strip(rstrip_chars)
                              #print ('**', ent)
                              if not ent or to_int (ent) is not None:
                                continue # this isn't an address
                              #TODO strip stopwords on either end of an ent for addresses - whether or not libpostal is installed
                        else:
                          pass
                          #print ('problem with address', address)
                        #print ('parse address', ent, '***', address)
                      #now let's check context, block lists and turn all occurances of ent in this sentence into a span mention and also check for context and block words
                      len_ent = len(ent)
                      while True:
                        if not ent or ent not in sentence2:
                          break
                        else:
                          i = sentence2.index(ent)
                          j = i + len_ent
                          if potential_context or block:
                              len_sentence2 = len(sentence2)
                              left = " "+ sentence2[max(0, i - context_window) : i].replace(",", " ").lower()+ " "
                              right = " "+ sentence2[j : min(len_sentence2, j + context_window)].replace(",", " ").lower() + " "
                              found_context = False
                              ent_lower = " "+ent.replace(",", " ").lower()+ " "
                              if context:
                                for c in context:
                                  c = c.lower()
                                  if is_cjk:
                                      if c in left or c in right or c in ent_lower:
                                          found_context = True
                                          break
                                  else:
                                      if (" "+c+" " in left or " "+c+" " in right or " "+c+" " in ent_lower):
                                          found_context = True
                                          #print ('foound context', c)
                                          break
                              else:
                                found_context = True
                              if block:
                                for c in block:
                                  new_tag = None
                                  if type(c) is tuple:
                                    c, new_tag = c
                                  c = c.lower()
                                  if is_cjk:
                                      if c in left or c in right or c in ent_lower:
                                          if new_tag is not None:
                                            tag = new_tag #switching the tag to a subsumed tag. DATE=&gt;AGE
                                            break
                                          else:
                                            found_context = False
                                            break
                                  else:
                                      if (" "+c+" " in left or " "+c+" " in right or " "+c+" " in ent_lower):
                                          if new_tag is not None:
                                            tag = new_tag #switching the tag to a subsumed tag. DATE=&gt;AGE
                                            break
                                          else:
                                            found_context = False
                                            break                                    
                              if not found_context:
                                delta += j
                                sentence2 = sentence2[i+len(ent):]
                                continue
                          #check to see if the entity is really a standalone word or part of another longer word.
                          # for example, we wont match a partial set of very long numbers as a 7 digit ID for example
                          if is_cjk or ((i+delta == 0 or sentence2[i-1]  in lstrip_chars) and (j+delta &gt;= len_sentence-1 or sentence2[j] in rstrip_chars)): 
                            all_ner.append((ent, delta+i, delta+j, tag, extra_weight))
                          sentence2 = sentence2[i+len(ent):]
                          delta += j

      all_ner = list(set(all_ner))
      # let's remove overlapping 
      # sort by length and position, favoring non-IDs first using the precedence list, 
      # and additionaly giving one extra weight to language specific regex (as opposed to default rules).
      # NOTE: this doesn't do a perfect overlap match; just an overlap to the prior item.
      all_ner.sort(key=lambda a: a[1]+(1.0/(1.0+(100*((precedence.get(a[3], min(20,len(a[3])))+a[4]))+a[2]-a[1]))))
      #print (all_ner)
      if not tag_type or 'ID' in tag_type:
        # now do overlaps prefering longer ents, and higher prededence items over embedded IDs or dates, etc.
        all_ner2 = []
        prev_mention = None
        for mention in all_ner:
          if prev_mention:
            if (prev_mention[1] == mention[1] and prev_mention[3] == mention[3] and prev_mention[4] &gt; 0 and prev_mention[4] != mention[4]) or\
              (prev_mention[2] &gt;= mention[1] and prev_mention[2] &gt;= mention[2]): 
                continue
            else:
              prev_mention = mention
          else:
            prev_mention = mention
          all_ner2.append(mention[:4])
        all_ner = all_ner2
      #TODO - refactor to check the tag_type list instead to do filtering.
      if no_address:
         all_ner = [a for a in all_ner if a[3] != 'ADDRESS']
      if no_id:
         all_ner = [a for a in all_ner if a[3] != 'ID']   
      if no_date:
         all_ner = [a for a in all_ner if a[3] != 'DATE']           
      return all_ner</code></pre>
      </details>
  </div>

</div>

<div class="doc doc-object doc-function">



<h2 id="pii_manager.ent_2_stdnum_type" class="doc doc-heading">
<code class="highlight language-python">ent_2_stdnum_type(text, src_lang=None)</code>

</h2>


  <div class="doc doc-contents ">
  
      <p>given a entity mention and the src_lang, determine potentially stdnum type</p>

      <details class="quote">
        <summary>Source code in <code>src/pii_manager.py</code></summary>
        <pre class="highlight"><code class="language-python">def ent_2_stdnum_type(text, src_lang=None):
  """ given a entity mention and the src_lang, determine potentially stdnum type """
  stdnum_type = []
  if src_lang is None:
    items = list(stdnum_mapper.items())
  else:
    l1 =  lang_2_stdnum.get(src_lang, []) + lang_2_stdnum.get('default', [])
    items = [(a1, stdnum_mapper[a1]) for a1 in l1]

  for ent_type, validate in items:
    try:
      found = validate(text)
    except:
      found = False
    if found:
      stdnum_type.append (ent_type)
  return stdnum_type</code></pre>
      </details>
  </div>

</div>

<div class="doc doc-object doc-function">



<h2 id="pii_manager.is_fast_date" class="doc doc-heading">
<code class="highlight language-python">is_fast_date(ent, int_arr=None, year_start=1600, year_end=2050)</code>

</h2>


  <div class="doc doc-contents ">
  
      <p>search for patterns like, yyyy-mm-dd, dd-mm-yyyy, yyyy-yyyy</p>

      <details class="quote">
        <summary>Source code in <code>src/pii_manager.py</code></summary>
        <pre class="highlight"><code class="language-python">def is_fast_date(ent, int_arr=None, year_start=1600, year_end=2050):
  """search for patterns like, yyyy-mm-dd, dd-mm-yyyy, yyyy-yyyy """
  if int_arr:
    len_int_arr = len(int_arr)
    if len_int_arr == 1 or len_int_arr &gt; 3: return False
  if int_arr is None:
    ent_arr = ent.replace("/", "-").replace(" ","-").replace(".","-")
    if not ("-" in ent_arr and ent_arr.count("-") &lt;=2): return False
    int_arr = [(e, to_int(e)) for e in ent_arr.split("-")]
  is_date = False
  has_year = has_month = has_day = 0
  for e, val in int_arr:
    if val is None: 
      break
    if (val &lt;= year_end and val &gt;= year_start):
      has_year +=1
    elif val &lt;= 12 and val &gt;= 1:
      has_month += 1
    elif val &lt;= 31 and val &gt;= 1:
      has_day += 1
    else:
      return False
  if (has_year == 1 and has_month == 1) or \
        (has_year == 2 and has_month == 0 and has_day == 0) or \
        (has_year == 1 and has_month == 1 and has_day == 1):
      return True
  return False</code></pre>
      </details>
  </div>

</div>

<div class="doc doc-object doc-function">



<h2 id="pii_manager.test_is_date" class="doc doc-heading">
<code class="highlight language-python">test_is_date(ent, tag, sentence, len_sentence, is_cjk, i, src_lang, sw, year_start=1600, year_end=2050)</code>

</h2>


  <div class="doc doc-contents ">
  
      <p>Helper function used to test if an ent is a date or not
We use dateparse to find context words around the ID/date to determine if its a date or not.
For example, 100 AD is a date, but 100 might not be.</p>

<details class="input">
  <summary>Input</summary>
  <p>:ent: an entity mention
:tag: either ID or DATE
:sentence: the context
:is_cjk: if this is a Zh, Ja, Ko text
:i: the position of ent in the sentence</p>
</details>      <p>Returns:
    (ent, tag): potentially expanded ent, and the proper tag. 
    Could return a potentially expanded ent, and the proper tag. 
    Returns ent as None, if originally tagged as 'DATE' and it's not a DATE and we don't know what it is.</p>

      <details class="quote">
        <summary>Source code in <code>src/pii_manager.py</code></summary>
        <pre class="highlight"><code class="language-python">def test_is_date(ent, tag, sentence, len_sentence, is_cjk, i, src_lang, sw, year_start=1600, year_end=2050):
    """
    Helper function used to test if an ent is a date or not
    We use dateparse to find context words around the ID/date to determine if its a date or not.
    For example, 100 AD is a date, but 100 might not be.
    Input:
      :ent: an entity mention
      :tag: either ID or DATE
      :sentence: the context
      :is_cjk: if this is a Zh, Ja, Ko text
      :i: the position of ent in the sentence
     Returns:
        (ent, tag): potentially expanded ent, and the proper tag. 
        Could return a potentially expanded ent, and the proper tag. 
        Returns ent as None, if originally tagged as 'DATE' and it's not a DATE and we don't know what it is.

    """
    # perform some fast heuristics so we don't have to do dateparser
    len_ent = len(ent)
    if len_ent &gt; 17 or (len_ent &gt; 8 and to_int(ent)):
      if tag == 'DATE': 
        #this is a very long number and not a date
        return None, tag
      else:
        #no need to check the date
        return ent, tag 

    if not is_cjk:
      if i &gt; 0 and sentence[i-1] not in lstrip_chars: 
        if tag == 'DATE': 
          return None, tag
        else:
          return ent, tag
      if i+len_ent &lt; len_sentence - 1 and sentence[i+len_ent+1] not in rstrip_chars: 
        if tag == 'DATE': 
          return None, tag
        else:
          return ent, tag

    int_arr = [(e, to_int(e)) for e in ent.replace("/", "-").replace(" ","-").replace(".","-").split("-")]
    if is_fast_date(ent, int_arr): 
      #this is most likely a date
      return ent, 'DATE'

    for e, val in int_arr:
      if val is not None and len(e) &gt; 8:
        if tag == 'DATE': 
          #this is a very long number and not a date
          return None, tag

    #test if this is a 4 digit year. we need to confirm it's a real date
    is_date = False
    is_4_digit_year = False
    if tag == 'DATE' and len_ent == 4:
      e = to_int(ent)
      is_4_digit_year = (e &lt;= year_end and e &gt;= year_start)

    #now do dateparser
    if not is_4_digit_year:
      try:
        is_date =  dateparser.parse(ent, languages=[date_parser_lang_mapper.get(src_lang,src_lang)]) # use src_lang to make it faster, languages=[src_lang])
      except:
        is_date =  dateparser.parse(ent, languages=["en"])  
    if (not is_date and tag == 'DATE') or (is_date and tag == 'ID'):
        j = i + len_ent
        #for speed we can just use these 6 windows to check for a date.
        #but for completeness we could check a sliding window. 
        #Maybe in some countries a year could
        #be in the middle of a date: Month Year Day
        ent_spans = [(-3,0), (-2, 0), (-1, 0), \
              (0, 3), (0, 2), (0, 1)]
        before = sentence[:i]
        after = sentence[j:]
        if before and not is_cjk and before[-1] not in lstrip_chars:
          is_date = False
        elif after and not is_cjk and after[0] not in rstrip_chars:
          is_date = False
        else:
          if  not is_cjk:
            before = before.split()
            after = after.split()
          len_after = len(after)
          len_before = len(before)
          for before_words, after_words in ent_spans:
            if after_words &gt; len_after: continue
            if -before_words &gt; len_before: continue 
            if before_words == 0: 
                before1 = []
            else:
                before1 = before[max(-len_before,before_words):]
            after1 = after[:min(len_after,after_words)]
            if is_cjk:
              ent2 = "".join(before1)+ent+"".join(after1)
            else:
              ent2 = " ".join(before1)+" "+ent+" "+" ".join(after1)
            if ent2.strip() == ent: continue
            try:
              is_date = dateparser.parse(ent2, languages=[date_parser_lang_mapper.get(src_lang,src_lang)])# use src_lang to make it faster, languages=[src_lang])
            except:
              is_date = dateparser.parse(ent, languages=["en"])
            if is_date:
              #sometimes dateparser says things like "in 2020" is a date, which it is
              #but we want to strip out the stopwords.
              if before1 and before1[-1].lower() in sw:
                before1 = before1[:-1]
              if after1 and after1[0].lower() in sw:
                after1 = after1[1:]
              if is_cjk:
                ent2 = "".join(before1)+ent+"".join(after1)
              else:
                ent2 = " ".join(before1)+" "+ent+" "+" ".join(after1)
              ent = ent2.strip()
              tag = "DATE"
              return ent, tag

    if tag == 'DATE' and not is_date:
      return None, tag

    return ent, tag</code></pre>
      </details>
  </div>

</div>



  </div>

  </div>

</div>
              
            </div>
          </div><footer>
    <div class="rst-footer-buttons" role="navigation" aria-label="Footer Navigation">
        <a href="../pdf_and_ocr/" class="btn btn-neutral float-left" title="pdf_and_ocr"><span class="icon icon-circle-arrow-left"></span> Previous</a>
        <a href="../searcher_indexer/" class="btn btn-neutral float-right" title="searcher_indexer">Next <span class="icon icon-circle-arrow-right"></span></a>
    </div>

  <hr/>

  <div role="contentinfo">
    <!-- Copyright etc -->
  </div>

  Built with <a href="https://www.mkdocs.org/">MkDocs</a> using a <a href="https://github.com/readthedocs/sphinx_rtd_theme">theme</a> provided by <a href="https://readthedocs.org">Read the Docs</a>.
</footer>
          
        </div>
      </div>

    </section>

  </div>

  <div class="rst-versions" role="note" aria-label="Versions">
  <span class="rst-current-version" data-toggle="rst-current-version">
    
    
      <span><a href="../pdf_and_ocr/" style="color: #fcfcfc">&laquo; Previous</a></span>
    
    
      <span><a href="../searcher_indexer/" style="color: #fcfcfc">Next &raquo;</a></span>
    
  </span>
</div>
    <script>var base_url = '../..';</script>
    <script src="../../js/theme_extra.js" defer></script>
    <script src="../../js/theme.js" defer></script>
      <script src="../../search/main.js" defer></script>
    <script defer>
        window.onload = function () {
            SphinxRtdTheme.Navigation.enable(true);
        };
    </script>

</body>
</html>
